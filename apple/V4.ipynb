{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea8428b",
   "metadata": {},
   "source": [
    "# V4\n",
    "* 각각의 이미지가 (1000,1000)의 픽셀을 가져 너무 많은 연산에 의해 코드를 실행할 수 없으니 차원 축소\n",
    "* Train Data에 적용하려면 시간이 오래 걸리므로 우선 Validation Data를 사용하여 각각의 이미지 픽셀 수 조정\n",
    "* 우선 픽셀수만 변경해서 fit 시켜보고 메모리 문제 또 뜨면 각 이미지 gray 처리하자\n",
    "* label을 문자열로 해놨었는데 int형으로 변환해주니 에러 발생하지 않음\n",
    "* 이제 Training Data에 적용하러 V5로 가자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360621c8",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f919d874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 15:15:21.955510: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-05 15:15:22.586515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4053 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:b3:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf1\n",
    "# import tensorflow as tf2\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.05\n",
    "session = tf1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6392f205",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be17fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f2d13",
   "metadata": {},
   "source": [
    "# Validation 파일안의 모든 이미지 픽셀수 변경 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92f7e27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원하는 주소 안에있는 png로 끝나는 파일들 모두 (28,28)로 형태 변환\n",
    "def fixel(image_path):\n",
    "    img_list = os.listdir(image_path)\n",
    "    img_list_jpg = [img for img in img_list if img.endswith(\".png\")]\n",
    "\n",
    "    lst = []\n",
    "    for i in img_list_jpg:\n",
    "        img = Image.open(image_path + i)\n",
    "        img = img.resize((28,28))\n",
    "        img_array = np.array(img)\n",
    "        lst.append(img_array)\n",
    "        \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28e86c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_L = fixel(\"Data/Validation/L/\")\n",
    "Val_M = fixel(\"Data/Validation/M/\")\n",
    "Val_S = fixel(\"Data/Validation/S/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35b61aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 28, 28, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = Val_L + Val_M + Val_S\n",
    "\n",
    "X_val_np = np.array(X_val)\n",
    "\n",
    "X_val_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c96ffdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = []\n",
    "\n",
    "for i in [\"L\", \"M\", \"S\"]:\n",
    "    for j in range(340):\n",
    "        y_val.append(i)\n",
    "        \n",
    "y_val_np = np.array(y_val)\n",
    "y_val_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67fd7cd",
   "metadata": {},
   "source": [
    "# y_val_np 문자열을 정수로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65ab162",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_np = np.where(y_val_np == \"L\", 0, y_val_np)\n",
    "y_val_np = np.where(y_val_np == \"M\", 1, y_val_np)\n",
    "y_val_np = np.where(y_val_np == \"S\", 2, y_val_np)\n",
    "\n",
    "y_val_np = y_val_np.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3c188",
   "metadata": {},
   "source": [
    "# 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e5b0ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_val_np, y_val_np,\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4674e55d",
   "metadata": {},
   "source": [
    "# 학습\n",
    "* 우선 실행되는지만 확인하기 위해 Validation Data를 사용하여 학습시켜본거임\n",
    "* Training Data로 학습해보고 실행되면 이제 layer 조정할거임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abdaf539",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 13, 13, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 11, 11, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 5, 5, 32)          4640      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 2, 2, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 32)          9248      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 1, 1, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,098\n",
      "Trainable params: 19,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 15:18:44.461066: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8204\n",
      "2022-11-05 15:18:45.196195: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-05 15:18:45.924753: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 3s 12ms/step - loss: 2.1892 - accuracy: 0.3885\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.9507 - accuracy: 0.5380\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.8116 - accuracy: 0.6275\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6618 - accuracy: 0.7292\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5502 - accuracy: 0.7855\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5154 - accuracy: 0.7757\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.4394 - accuracy: 0.8223\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.3906 - accuracy: 0.8493\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.3107 - accuracy: 0.8762\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.3139 - accuracy: 0.8799\n",
      "7/7 - 0s - loss: 0.4407 - accuracy: 0.8333 - 184ms/epoch - 26ms/step\n",
      "0.4406760334968567 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding=\"same\"),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding=\"same\"),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "  tf.keras.layers.Dense(32, activation='relu'),\n",
    "    \n",
    "    \n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(loss, acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
